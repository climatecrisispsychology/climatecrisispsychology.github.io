## Factors in Climate Change Belief Formation

Matthew Tran Radovan

Stanford University

## Intro

Beliefs about climate change - whether it's caused by humans, and whether it exists in the first place - vary across the United States [[(Marlon et al., 2022)]{.underline}]. As a result, it's important to consider how these variations in belief come to be, both via how they form in the first place and how they may change over time. The psychology literature in general gives us a wide range of cognitive biases to explore and insights into how each one operates and affects beliefs, but climate change-specific psychology literature is much sparser. As a result, this chapter focuses on just a few aspects of the belief updating process and factors that affect it.

We first discuss motivated reasoning, a major factor that influences belief in climate change. The process of forming and updating their beliefs with the goal of arriving at a specific belief has been shown to affect how individuals update their beliefs about climate change topics, suggesting that mitigating motivated reasoning may help promote more accurate and rational climate belief updating. Some studies take steps towards confirming this hypothesis, providing first steps towards understanding how factors that negatively affect climate change beliefs can be mitigated.

The chapter then switches to information reception and misinformation susceptibility, analyzing how misinformation is taken into account in individuals' beliefs and potentially repeated and spread. Much like the literature surrounding motivated reasoning, much of the misinformation literature surrounds political polarization topics in general. However, many climate change psychology papers (such as in Hart and Nisbet (2012) and Caddick and Feist (2022), discussed later) show political polarization to be correlated with climate beliefs, and thus these topics are closely tied. Additionally, the factors that correlate with susceptibility to misinformation tend to be similar to the factors driving motivated reasoning. Beyond the effects of misinformation, we find work that demonstrates potential counters to the effects of misinformation, which also have some overlap with motivated reasoning.

Finally, we discuss some Bayesian methods to model belief updating. One such paper discusses a general framework for updating individual beliefs from the prior belief to the posterior belief given new information, and demonstrates how the framework clarifies the potential for cognitive biases to be incorrectly assumed. On the other hand, another paper demonstrates a Bayes net approach to modeling climate change beliefs, and shows that the Bayes net can capture the effects of various factors on climate change beliefs regardless of whether cognitive biases such as motivated reasoning came into play. As a result, we can consider potential methods to identify the most influential factors on climate change beliefs and prioritize studying either how those factors influence climate change beliefs or how to mitigate any negative effects of those factors on belief.

Motivated reasoning, misinformation, and Bayesian belief modeling are, at first glance, somewhat disparate topics. However, susceptibility to misinformation seems to be driven at least in part by motivated reasoning, both of which are factors that influence individuals' climate change beliefs. And, taking a step back at climate beliefs as a whole, belief modeling is a powerful tool that can allow us to more deeply understand the influences of factors such as motivated reasoning and misinformation.

## Motivated Reasoning

When individuals consider new information that differs from their current beliefs about the world, they may have a goal in mind. Any instance of this is known as motivated reasoning, as the individual is motivated by a goal when reasoning about their beliefs and new information. Typically, this is an *accuracy goal*: the attempt to come to the most accurate belief possible relative to the ground truth of the matter. This goal is non-directional, as the individual does not attempt to direct their reasoning towards any specific goal, and also requires significant cognitive overhead in order to process and analyze information more deeply. However, the individual may also have a *directional goal*, where they bias their reasoning in an attempt to arrive at a predetermined conclusion [[(Z. Kunda, 1990)]{.underline}]. This is not simply concluding that their desired belief is correct - rather, they must come up with ways, whether consciously or subconsciously, to find evidence supporting their belief, bringing in other cognitive factors. One such cognitive factor is a confirmation bias, which is distinct from, but overlaps with, motivated reasoning. [[Klayman (1995)]{.underline}] discusses multiple ways that confirmation biases may occur: for instance, initial overconfidence may lead to continued overconfidence in the belief even after evidence is appropriately considered. Similarly related to motivated reasoning, the prior attitude effect is the effect by which individuals assess the trustworthiness of new information based on how well it aligns with their predetermined directional goal. One such example of this effect is a study by [[Taber and Lodge (2006)]{.underline}], which found that in a politically polarized setting, the prior attitude effect strongly affects individuals' reception and processing of new information.

However, to dive more specifically into climate psychology, we first must address the effects that motivated reasoning has on climate change beliefs. Literature surrounding motivated reasoning's effects on climate change psychology is somewhat sparse, but some studies do exist. For instance, the study by [[Hart and Nisbet (2012)]{.underline}] on climate mitigation policies found that the introduction of social distance between subjects and the victims of climate change effects caused Democrats to increase their support of, and Republicans to decrease their support of, climate mitigation policies, relative to the control of no social distance message activation. They claim that this is due to the effects of motivated reasoning in terms of issue support. However, it is also possible that belief in human-induced global warming was the driving force behind the motivated reasoning effect, as this factor was stronger than the political partisanship factor in their models. In any case, it seems reasonable to conclude from Hart and Nisbet's study that there does exist some sort of influence that motivated reasoning has on support of climate change policies. This is separate from belief, but arguably stronger than belief as it's a specific action that presumably would require belief in climate change as a prerequisite.

Aside from motivated reasoning's effects on individuals' tendency towards climate action, motivated reasoning also seems to have effects on social cognition. [[Nir (2011)]{.underline}] studied motivated reasoning's social effects with the starting assumption of relevance being that the public, rather than individuals, form opinions as a whole. The study goes on to find that, in the political setting, individuals with directional goals tend to overestimate public support while individuals with accuracy goals tend to underestimate public support for political opinions. Although not specifically climate change-related, climate change psychology and motivated reasoning has been tied to political polarization in many of the articles discussed in this chapter, and this concept is discussed in further length in the Social Identity chapter. As a result, it's not unreasonable to argue for extending Nir's result to the polarized subject of climate change belief.

The studies discussed thus far have presumed motivated reasoning as the default method of non-rational belief updating in their experimental designs; one could argue that they should instead investigate whether motivated reasoning (as opposed to any other effects) are the actual drivers of the non-rational belief updating. [[Thaler (2020)]{.underline}] attempted to address this issue by designing an experiment surrounding trust in news to identify motivated reasoning, starting with the assumption of standard Bayesian belief updating. Although it considers only individuals' reception of articles in a vacuum, without considering the effect of external factors such as the source of the news articles, Thaler claims that this study results in a potential framework to identify whether motivated reasoning is a factor in individuals' belief updating processes. As a result, it may be reasonable to apply this same framework to studies such as those discussed previously to better certify that motivated reasoning was truly the driving force in the studies' results.

With the effects of motivated reasoning on climate change better understood, we must understand factors that promote motivated reasoning in order to then lower the impacts of motivated reasoning. One such study, by [[Caddick and Feist (2022)]{.underline}], did exactly this: they searched for predictors of motivated reasoning in the climate change setting. By presenting two fictional scientists' articles on climate change (one for and one against human-driven climate change, but both with equally flawed reasoning), they found support for the hypotheses that cognitive style, personality, and ideology were predictors of motivated reasoning. Although the effect size was small and many factors were interrelated, they found that dogmatism and authoritarianism/conservatism/traditionalism increased motivated reasoning effects, while individuals with higher dispositional anxiety correlated with lower motivated reasoning effects. However, individuals with higher "adoption of scientific attitudes" and "need for cognition" were not found to show a greater degree of motivated reasoning. Additionally, the study objectively defined motivated reasoning by quantifying how balanced the participants were in identifying both the strengths and weaknesses of both articles: for instance, a high motivated reasoning score was assigned to subjects who focused primarily of the weaknesses of the view they disagreed with and the strengths of the view they agreed with. Because the study quantifies motivated reasoning this way, it provides a fairly strong argument for its findings.

[[Stenhouse et al. (2018)]{.underline}] studied a singular factor: investigating the effects of Actively Open-Minded Thinking (AOT) on mitigating partisanship-driven motivated reasoning, where AOT is defined as "the tendency to evaluate arguments and evidence without undue bias from one\'s own prior beliefs" [[(Mellers et al., 2015)]{.underline}]. Inversely, low tendency for AOT means higher bias from one's prior beliefs, and therefore a stronger tendency to be biased towards maintaining prior beliefs, while high tendency for AOT also means increased active processing of information counter to the individual's current belief. When investigating the effects of AOT, Stenhouse et al. found a correlation between higher AOT tendencies and higher belief in human-caused global warming, notably regardless of political ideology or scientific knowledge.

With directional motivated reasoning established as a relevant factor in climate change belief formation and an understanding of the factors that correlate with tendencies towards directional goals, we can approach how to promote accuracy-driven reasoning, or even mitigate motivated reasoning entirely. [[Redlawsk et al. (2010)]{.underline}] investigated an "affective tipping point" in the context of political opinions which, after being reached, drives individuals around their goal-oriented motivated reasoning to more accurately update their beliefs. Their study centered around individuals' voting behavior towards candidates that they hold a positive affect towards. Typically, motivated reasoning would drive these individuals to strengthen their opinion of their candidate regardless of new information; however, Redlawsk et al. found that there was a threshold of new, negative information caused individuals to switch to accuracy-driven or rational reasoning, hypothesized to be due to the anxiety caused by cognitive dissonance.

Similarly, [[Gehlbach et al. (2019)]{.underline}] investigated an intervention to promote cognitive consistency. They began by noting that people often engage in a form of motivated reasoning in order to maintain consistency with the beliefs of others in their social network, which is one factor that causes climate change skepticism. To counteract this effect, they primed their subjects' via a survey of the subjects' general science beliefs; subsequently, primed conservative subjects tended to report higher belief in climate change than unprimed conservatives subjects. This result suggests an alternative intervention to Redlawsk et al.'s proposition: instead of overloading individuals with information, prime them to think about their beliefs in science in general in order to promote climate change beliefs.

Although the literature of motivated reasoning's relationships to climate change beliefs are limited overall, the studies that exist show that individuals do have a tendency to engage in motivated reasoning to guide the development of their climate change beliefs. This can be problematic because higher levels of motivated reasoning imply a lower drive towards an accuracy goal, in turn meaning that individuals become unconsciously less interested in understanding the actual scientific consensus on climate change. Multiple factors have been implicated in individuals' likelihoods to engage in motivated reasoning, but one consistent factor has been political affiliation. Simply understanding these factors is not enough to drive actionable change in individuals beliefs; however, other studie\<s such as the two discussed, go on to directly investigate the efficacy of various potential interventions to decrease the effects of motivated reasoning. These seem to go in two directions: one discusses the continual introduction of information until it effectively "overloads" the effects of motivated reasoning, and the other promotes a certain style of thinking, though it only serves as an introduction to the topic and does not fully discuss how the intervention may be applied. These results suggest that, although not necessarily well fleshed out, there may be potential ways to mitigate the known effects of motivated reasoning on individuals' climate change beliefs.

## Information & misinformation

Up to this point, we've primarily discussed how individuals decide whether to use presented information to update their belief, with the implicit assumption that any information that they do use to update their belief is true. However, this is a strong assumption - misinformation as a whole has frequently been in the recent news, covering topics from elections to COVID, and climate misinformation is no different. Additionally, public perception of the news has followed: trust in both national and local news has significantly decreased in the past 8 years [[(Watson, 2022)]{.underline}]. As a result, it's important to consider the relationships between misinformation and individuals' beliefs.

[[Treen et al. (2020)]{.underline}] provide a comprehensive review of climate change misinformation that serves as a good overview and introduction to the topic. They begin by defining misinformation as misleading information, regardless of intent to mislead, and discuss the variety of actors (such as governments and industries) that are involved in climate science denial (and thus climate misinformation). They then discuss how this climate change misinformation spreads and what its effects are. First, they note confirmation bias as one of the primary psychological factors contributing to individuals' decisions to spread misinformation, but find that there's little research regarding the spread of climate misinformation in particular. From this brief introduction, we can begin to see the correlations between motivated reasoning and misinformation susceptibility. Continuing in the review, the effects of climate change misinformation discussed are detailed: creation of doubts about the existence and urgency of climate change as well as validity of climate change scientists, increase in political polarization, and emotional responses are all results of climate misinformation within the population misinformation susceptibility.

To understand the interactions between misinformation and climate change beliefs more deeply, we first have to understand how misinformation spreads and is consumed by individuals. Key factors influencing susceptibility to fake news, and its relationship to political partisanship, were investigated by [[Pennycook and Rand (2019)]{.underline}]. Generally, they found that a higher propensity for analytical reasoning positively correlated with the ability to distinguish between real and fake news, both full articles and headlines, regardless of partisanship, but this ability was stronger for news articles that were ideologically aligned with the subject. From this, they concluded that partisan bias is likely only a partial driver of fake news susceptibility, and instead suggest that individuals who are susceptible to fake news simply do not bother to actively reason about the veracity of news articles and headlines. In other words, the key takeaway is not necessarily that there is any motivation to believe misinformation, but there is no accuracy goal, either: individuals who are susceptible to misinformation simply don't put in effort to determine their trust in the information.

On the other hand, some studies do draw relationships between political polarization and misinformation susceptibility. [[Traberg and van Linden (2022)]{.underline}] also investigated factors that make individuals more susceptible to believing misinformation, and their key results highlighted the same importance of political polarization found throughout most papers discussed in this chapter: individuals are more susceptible to misinformation when the source presented to them aligns with their previous political ideologies. Similarly, [[Van der Linden (2022)]{.underline}] looked into susceptibility to misinformation, as well as the spread of and immunization against misinformation, in their conceptual review. Their review found two primary factors for misinformation susceptibility: insufficient consideration of accuracy cues and motivation to reinforce social/political identities and beliefs. Likelihood to spread misinformation was especially affected by the latter factor, but van der Linden notes that most online misinformation originates from relatively few accounts (e.g. superspreaders).

Much like the subject of motivated reasoning, there's little recent research on the interactions between misinformation and climate change. However, the previously mentioned studies discuss misinformation in the context of politically polarized topics and especially COVID-19. As a result, it's reasonable to draw parallels to climate misinformation, as climate change psychology heavily implicates political polarization as a major factor in belief. And, in the case of COVID-19, both subjects are highly politicized despite being grounded in scientific consensus. So, although not the exact same subject, these studies cover similar enough topics to draw reasonable initial conclusions. All these considerations taken into account, there are two major themes: directional goals of socio-political identity reinforcement (i.e. political affiliation/polarization) and lack of accuracy goals are the key drivers of misinformation susceptibility. In other words, interventions to reduce the effects of directionally motivated reasoning may assist with decreasing misinformation susceptibility.

As with motivated reasoning, understanding what makes individuals susceptible to misinformation is an important first step, but understanding how to prevent susceptibility to misinformation is necessary for more accurate belief updating. The following studies further investigate interventions to reduce misinformation susceptibility, and begin by defining the term "inoculations" for preventative steps prior to misinformation exposure.

In the previously discussed review, Treen et al. also proposed methods to combat climate misinformation. Two possibilities can operate on the individual level, as discussed later in this section: inoculation against misinformation and directly combating misinformation by correcting misinformation with facts. Two other possibilities operate on a platform, rather than individual, level by preventing individuals from interacting with misinformation in the first place by either rapidly detecting malicious accounts or better ranking algorithms. These platform-level interventions inherently depend on the platform's cooperation, and thus have a much higher barrier to study and implementation, but have the potential to be wider-spread and thus may be more powerful at a population level.

Van der Linden (2022), in their previously mentioned paper, argues that pre-exposure misinformation inoculations are at least as important as post-exposure inoculations due to the lasting effects of misinformation exposure. In fact, their best-practice inoculation recommendation has four parts: introduce the facts of the situation, warn about the misinformation specific to those facts, explain why the misinformation is incorrect, and reinforce the original facts and explanation. They note some possible drawbacks, including potential backfiring (having individuals reinforce their belief in the misinformation), inoculations struggle to have the same reach as the original misinformation, and even after acknowledging that misinformation is incorrect, individuals may still base beliefs on that misinformation. The latter two are factors that diminish the potential full effect of inoculations. However, the first potential drawback is potentially an effect of motivated reasoning, and may be able to be dealt with through a motivated reasoning lens.

[[Van der Linden et al. (2017)]{.underline}] studied climate change misinformation interventions as well by introducing the idea of inoculation against climate change misinformation, defined in their paper by forewarning individuals of potential misinformation and preemptively debunking misinformation. They separate these types of misinformation inoculation into general and detailed inoculation, designating how specific the forewarning and debunking statements were. Their study began with the base knowledge that communicating the existence of scientific consensus on climate change helps people believe that the scientific consensus exists, and finds that the misinformation does indeed have a negative effect on that belief regardless of whether the initial positive communication existed. It also found that both general and detailed inoculations against climate misinformation helps negate the effect of misinformation on that belief. It's important to note that van der Linden et al. studied effects on belief in scientific consensus as a proxy for individuals' beliefs in climate change.

One platform-level intervention was studied by [[Lutzke et al. (2019)]{.underline}][]: specifically, interventions for climate change misinformation on Facebook. Having subjects read a series of guidelines for evaluating news online (i.e. priming them to be exposed to misinformation) caused a reduced likelihood of both believing and repeating fake news about climate change, but didn't reduce likelihood to to believe or repeat legitimate news. Their study found small but significant effect sizes, and they make the reasonable claim that even small effect sizes are still important at the scales that misinformation on Facebook operates on.

Misinformation is a tricky subject: when considering it alone, without even considering its effects on consumers, there are many variables: how it's shared, the underlying intent behind its creator, and its spread, just to name a few. However, it's an extremely salient factor in the conversation surrounding climate change belief, and has been shown to both exist and have effects on individuals' beliefs. As a result, we focus on its effects on individuals, disregarding the platform-level issues of how misinformation spreads. Misinformation susceptibility, as with motivated reasoning, is highly correlated with political polarization and has a significant effect on climate change belief. However, there are interventions that have the potential to decrease the effects of misinformation on climate change beliefs, and even small effect sizes in the studies may have major impacts at high volumes of misinformation as seen today. Additionally, motivated reasoning seems to be a potentially strong factor in misinformation susceptibility, and thus provides another set of potential interventions to mitigate the issue.

## Belief updating

We've now discussed the effects of motivated reasoning and misinformation on climate change belief updating in depth, and have proposed potential interventions that can mitigate these negative effects. However, the idea of belief updating itself has been poorly defined, and in this section, we will discuss frameworks by which to model belief updating and better understand how the effects of motivated reasoning and misinformation may modify belief updating.

Bayesian belief updating, based on Bayes' rule, is a general framework to model the evolution of a belief (i.e. the posterior belief) given a prior belief and new evidence related to the belief. Bayes' rule declares that P(H \| D) = (P(H) \* P(D \| H)) / P(D) where H is the hypothesis and D is the evidence, or data. Here, we call P(H) the prior belief, P(D \| H) the (data) likelihood, P(D) the marginal likelihood, and P(H \| D) the posterior (or updated) belief. Typically, we ignore the marginal likelihood due to the infeasibility of calculating the probability of the new evidence as a whole, and instead say that the posterior belief is proportional to the prior multiplied by the likelihood. This model is purely "rational" in the sense that only the likelihood is considered when updating from the prior to the posterior.

This Bayesian updating framework also has the potential to model irrational belief updates, such as those in climate change, as illustrated by [[Druckman and McGrath (2019)]{.underline}]. They define the prior belief as the currently existing belief regarding any given climate change topic, and model the prior as a normal distribution with a mean centered at the individual's current belief and a variance based on the individual's uncertainty around their belief. They continue to model new information that comes in - seemingly merging the likelihood and marginal likelihood into one distribution - as being sampled from another normal distribution. These two distributions can then be combined via Bayesian inference rules, forming a posterior belief that is a function of the prior belief distribution and the incoming information distribution. The choice of the normal distribution used in the described model is somewhat arbitrary, chosen under the assumption that these distributions are indeed normal. However, replacing one distribution with another is straightforward, as the Bayesian update rule will work for any continuous distribution.

The most salient point that Druckman and McGrath make is that the distribution of new information, used to update the individual's prior belief, can be affected in a variety of ways. They begin with the assumption that, ideally, the distribution of new information is centered around the ground truth of the issue, and that the variance is based on the individual's perception of the credibility of incoming information. This standard method is in line with the idea of an accuracy goal in motivated reasoning, as individuals update their beliefs with the goal of approaching the most accurate possible belief.

The distribution of new information can then be used to more formally understand the effects of directional goals, but also how other effects may be mistaken for directional goals. One such example of the effects of a directional goal, confirmation bias causes a re-centering of the distribution of new information at the center of the individual's prior belief, meaning that new information is likely to reinforce the prior belief. Another example is the prior attitude effect, described by Druckman and McGrath as the individual\'s perceived confidence of new information being positively correlated with the similarity of that information to the individual\'s prior belief. Here, an accuracy goal may be mistaken for a directional goal: for instance, if the individual has low trust in science but high trust in a news source, they may reject science reports in favor of misleading news, which is due to an accuracy goal yet may seem to be directionally motivated. More generally, Druckman and McGrath describe the issue of directional versus accuracy goals as an issue with understanding trust: an individual with an accuracy goal may seem to be affected by motivated reasoning if they primarily trust sources that already share their views.

At first glance, the article by [[Cook and Lewandowsky (2016)]{.underline}] discusses similar concepts using a Bayesian framework. However, rather than discussing updating prior distributions into posterior distributions, they analyze the factors of belief updating in the context of a Bayes belief net: a directed graph of causal variables that can be used to understand how various factors influence the distribution or likelihood of a variable in question. In the context of climate change beliefs, Cook and Lewandowsky create a "worldview Bayes net" to model the interactions between the factors in a four-variable Bayes net. It's important to note that this method measured individuals' perceived scientific consensus on climate change rather than directly measuring individuals' belief in that scientific consensus. However, their method still displayed important results. Directly, they found that climate change belief updating was a function of individuals' support of free-market ideals (as a proxy for political affiliation) and thus belief updating is dependent on political polarization. But, further and more relevant to the underlying belief updating process, Cook and Lewandowsky showed that Bayes nets can be used to capture the effects of potentially "irrational" belief updates, such as the effects of politically-driven motivated reasoning, in a standard Bayesian setting.

These two papers taken together demonstrate something striking: there is potential to model climate change belief updating, taking into account any number of factors, using standard Bayesian models, and thus the direct possibility from those models to more deeply understand the impact of various factors on individuals' belief updates - regardless of "rationality" of those factors. However, Druckman and McGrath note that it can be difficult to differentiate accuracy and directional goals in the Bayesian setting, while Cook and Lewandowsky's model does not depend on this accurate differentiation. So, Bayesian modeling may not necessarily expose why certain factors are so influential - such as whether they're influential due to motivated reasoning versus due to secondary effects, as discussed by Druckman and McGrath - but instead the process simply highlights which factors are key to belief updating processes. Then, using this modeling as guidance to understand which factors to study more deeply can then lead to more targeted interventions to maximize the ability of interventions to promote accurate climate change beliefs.

## Conclusion

When considering the broad problem of climate change, one key step is understanding how individuals generate their beliefs about climate change, and especially understanding what factors cause individuals to hold inaccurate beliefs about climate change. The immediate next step is then to understand how to "correct" these factors to promote accurate climate change beliefs. In this chapter, we have explored the effects of motivated reasoning on climate beliefs, the relationship between motivated reasoning and misinformation, and methods to mitigate the effects of the two; we have also discussed two potential Bayesian models of climate belief updates.

Motivated reasoning was demonstrated to be a major underlying factor that influences climate beliefs away from being accurate. As a first step, multiple factors were found to be correlated with individuals' likelihood to engage in motivated reasoning, especially political polarization. But, beyond just identifying these factors, it is important to mitigate motivated reasoning's effects in order to guide individuals to more accurate beliefs about climate change. Some studies do indeed address potential interventions to mitigate the effects of motivated reasoning through two somewhat opposite methods: either simply overloading the individual with information until cognitive dissonance discomfort causes them to simply drop their directional goal, or by promoting thinking styles that make individuals less likely to engage in motivated reasoning.

To those engaged with the news in the past seven to eight years, misinformation is clearly an issue that has major implications, and climate misinformation is no exception. The factors that make individuals susceptible to motivated reasoning seem to be closely tied to those that are correlated with motivated reasoning, in part due to individuals' directional goals and in part due to their lack of accuracy goals. So, interventions that may mitigate the effects of directional goals may assist with reducing misinformation susceptibility. Interventions more directly focused on misinformation have been also proposed that may mitigate the effects of misinformation, both at an individual and a platform level.

Bayesian modeling helps frame the concepts of misinformation and motivated reasoning in the same context with the idea of belief updates: taking in new information and using it to form a new belief about a subject based on that new information and your previous belief. Although the models demonstrate that it may not be easy to clarify whether factors such as motivated reasoning are what cause seemingly "irrational" belief updates, they nonetheless can capture the effects of any potential irrational belief updating and can therefore be a powerful tool to identify factors that contribute to seemingly irrational belief updating, helping to prioritize climate psychology research.

## References

Caddick, Z. A., & Feist, G. J. (2021). When beliefs and evidence collide: psychological and ideological predictors of motivated reasoning about climate change. In Thinking & Reasoning (Vol. 28, Issue 3, pp. 428--464). Informa UK Limited. https://doi.org/10.1080/13546783.2021.1994009

Cook, J., & Lewandowsky, S. (2016). Rational Irrationality: Modeling Climate Change Belief Polarization Using Bayesian Networks. In Topics in Cognitive Science (Vol. 8, Issue 1, pp. 160--179). Wiley. https://doi.org/10.1111/tops.12186

Druckman, J. N., & McGrath, M. C. (2019). The evidence for motivated reasoning in climate change preference formation. In Nature Climate Change (Vol. 9, Issue 2, pp. 111--119). Springer Science and Business Media LLC. https://doi.org/10.1038/s41558-018-0360-1

Gehlbach, H., Robinson, C. D., & Vriesema, C. C. (2019). Leveraging cognitive consistency to nudge conservative climate change beliefs. In Journal of Environmental Psychology (Vol. 61, pp. 134--137). Elsevier BV. https://doi.org/10.1016/j.jenvp.2018.12.004

Hart, P. S., & Nisbet, E. C. (2011). Boomerang Effects in Science Communication. In Communication Research (Vol. 39, Issue 6, pp. 701--723). SAGE Publications. https://doi.org/10.1177/0093650211416646

Klayman, J. (1995). Varieties of Confirmation Bias. In Psychology of Learning and Motivation (pp. 385--418). Elsevier. https://doi.org/10.1016/s0079-7421(08)60315-1

Kunda, Z. (1990). The case for motivated reasoning. In Psychological Bulletin (Vol. 108, Issue 3, pp. 480--498). American Psychological Association (APA). https://doi.org/10.1037/0033-2909.108.3.480

Lutzke, L., Drummond, C., Slovic, P., & Árvai, J. (2019). Priming critical thinking: Simple interventions limit the influence of fake news about climate change on Facebook. In Global Environmental Change (Vol. 58, p. 101964). Elsevier BV. https://doi.org/10.1016/j.gloenvcha.2019.101964

Marlon, J., Neyens, L., Jefferson, M., Howe, P., Mildenberger, M., & Leiserowitz, A. (2023, February 18). Yale Climate Opinion Maps 2021. Yale Program on Climate Change Communication. https://climatecommunication.yale.edu/visualizations-data/ycom-us/

Mellers, B., Stone, E., Atanasov, P., Rohrbaugh, N., Metz, S. E., Ungar, L., Bishop, M. M., Horowitz, M., Merkle, E., & Tetlock, P. (2015). The psychology of intelligence analysis: Drivers of prediction accuracy in world politics. In Journal of Experimental Psychology: Applied (Vol. 21, Issue 1, pp. 1--14). American Psychological Association (APA). https://doi.org/10.1037/xap0000040

Nir, L. (2011). Motivated Reasoning and Public Opinion Perception. In Public Opinion Quarterly (Vol. 75, Issue 3, pp. 504--532). Oxford University Press (OUP). https://doi.org/10.1093/poq/nfq076

Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. In Cognition (Vol. 188, pp. 39--50). Elsevier BV. https://doi.org/10.1016/j.cognition.2018.06.011

Redlawsk, D. P., Civettini, A. J. W., & Emmerson, K. M. (2010). The Affective Tipping Point: Do Motivated Reasoners Ever "Get It"? In Political Psychology (Vol. 31, Issue 4, pp. 563--593). Wiley. https://doi.org/10.1111/j.1467-9221.2010.00772.x

Stenhouse, N., Myers, T. A., Vraga, E. K., Kotcher, J. E., Beall, L., & Maibach, E. W. (2018). The potential role of actively open-minded thinking in preventing motivated reasoning about controversial science. In Journal of Environmental Psychology (Vol. 57, pp. 17--24). Elsevier BV. https://doi.org/10.1016/j.jenvp.2018.06.001

Taber, C. S., & Lodge, M. (2006). Motivated Skepticism in the Evaluation of Political Beliefs. In American Journal of Political Science (Vol. 50, Issue 3, pp. 755--769). Wiley. https://doi.org/10.1111/j.1540-5907.2006.00214.x

Thaler, M. (2020). The Fake News Effect: Experimentally Identifying Motivated Reasoning Using Trust in News (Version 4). arXiv. https://doi.org/10.48550/ARXIV.2012.01663

Traberg, C. S., & van der Linden, S. (2022). Birds of a feather are persuaded together: Perceived source credibility mediates the effect of political bias on misinformation susceptibility. In Personality and Individual Differences (Vol. 185, p. 111269). Elsevier BV. https://doi.org/10.1016/j.paid.2021.111269

Treen, K. M. d'I., Williams, H. T. P., & O'Neill, S. J. (2020). Online misinformation about climate change. In WIREs Climate Change (Vol. 11, Issue 5). Wiley. https://doi.org/10.1002/wcc.665

van der Linden, S., Leiserowitz, A., Rosenthal, S., & Maibach, E. (2017). Inoculating the Public against Misinformation about Climate Change. In Global Challenges (Vol. 1, Issue 2, p. 1600008). Wiley. https://doi.org/10.1002/gch2.201600008

van der Linden, S. (2022). Misinformation: susceptibility, spread, and interventions to immunize the public. In Nature Medicine (Vol. 28, Issue 3, pp. 460--467). Springer Science and Business Media LLC. https://doi.org/10.1038/s41591-022-01713-6

  [[(Marlon et al., 2022)]{.underline}]: https://climatecommunication.yale.edu/visualizations-data/ycom-us/
  [[(Z. Kunda, 1990)]{.underline}]: https://pubmed.ncbi.nlm.nih.gov/2270237
  [[Klayman (1995)]{.underline}]: https://pages.ucsd.edu/~mckenzie/Klayman1995.pdf
  [[Taber and Lodge (2006)]{.underline}]: https://onlinelibrary.wiley.com/doi/full/10.1111/j.1540-5907.2006.00214.x
  [[Hart and Nisbet (2012)]{.underline}]: https://journals.sagepub.com/doi/pdf/10.1177/0093650211416646
  [[Nir (2011)]{.underline}]: https://academic.oup.com/poq/article/75/3/504/1833883?login=true
  [[Thaler (2020)]{.underline}]: https://scholar.harvard.edu/files/mthaler/files/mthaler_fake-news-effect_full.pdf
  [[Caddick and Feist (2022)]{.underline}]: https://www.tandfonline.com/doi/epdf/10.1080/13546783.2021.1994009?needAccess=true&role=button
  [[Stenhouse et al. (2018)]{.underline}]: https://www.sciencedirect.com/science/article/pii/S0272494418302834
  [[(Mellers et al., 2015)]{.underline}]: https://www.doi.org/10.1037/xap0000040
  [[Redlawsk et al. (2010)]{.underline}]: https://onlinelibrary.wiley.com/doi/10.1111/j.1467-9221.2010.00772.x
  [[Gehlbach et al. (2019)]{.underline}]: https://www.sciencedirect.com/science/article/pii/S0272494418302433#sec4
  [[(Watson, 2022)]{.underline}]: https://www.statista.com/statistics/707507/national-local-news-trust/
  [[Treen et al. (2020)]{.underline}]: https://wires.onlinelibrary.wiley.com/doi/full/10.1002/wcc.665
  [[Pennycook and Rand (2019)]{.underline}]: https://www.sciencedirect.com/science/article/pii/S001002771830163X?via%3Dihub
  [[Traberg and van Linden (2022)]{.underline}]: https://www.sciencedirect.com/science/article/pii/S0191886921006486?via%3Dihub
  [[Van der Linden (2022)]{.underline}]: https://www.nature.com/articles/s41591-022-01713-6
  [[Van der Linden et al. (2017)]{.underline}]: https://onlinelibrary.wiley.com/doi/full/10.1002/gch2.201600008
  [[Lutzke et al. (2019)]{.underline}]: https://www.sciencedirect.com/science/article/pii/S0959378019307009
  [[Druckman and McGrath (2019)]{.underline}]: https://www.nature.com/articles/s41558-018-0360-1
  [[Cook and Lewandowsky (2016)]{.underline}]: https://onlinelibrary.wiley.com/doi/full/10.1111/tops.12186
